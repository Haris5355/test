# RQ6: Tasks Other Than Code Complete

## Overview
This repository explores the generalization capabilities of the **Natural-DaCoDe** approach beyond code-specific tasks. Specifically, we evaluate its performance on normal text tasks, using the **WIKIMIA dataset** for text completion. The evaluation was conducted using **ChatGPT 3.5**, a versatile language model known for its efficacy in handling both code and natural language tasks.

The main objective of this evaluation is to assess the performance of our approach on non-code data and compare it with established baseline methods in the field.

## Methodology

### Text Completion Task
We applied **Natural-DaCoDe** to a text completion task where incomplete text was provided as input, and ChatGPT was tasked with generating the next segment of text. To evaluate the generated text, we used the **cosine similarity** metric, which measures the similarity between the generated text and the original. Higher cosine similarity values indicate better performance.

In addition to cosine similarity, we calculated the **naturalness** of both the incomplete and generated text using the methodology outlined in Section 3.3 of our paper.

### Classifier Training
To distinguish between contaminated and clean data, we trained an **SVM classifier** using the following features:
- Model performance (cosine similarity).
- Task difficulty (naturalness of the text).

The SVM classifier was trained on text files from the **WIKIMIA dataset**, as described in Section 4.2 of the paper.

## Results

The results of the evaluation are summarized in the following table:

| Approach       | Accuracy (%) | TPR (%) | FPR (%) | AUC (%) |
|----------------|--------------|---------|---------|---------|
| **Our Approach**       | **83.32**     | **84.11**    | **22.93**    | **88.00** |
| Min-K% Prob    | 68.31        | 76.09   | 37.98   | 74.00   |
| Loss Attack    | 62.12        | 64.03   | 41.21   | 64.00   |

### Key Insights:
- **Accuracy**: Our approach achieves **83.32%**, outperforming Min-K% Prob (68.31%) and Loss Attack (62.12%).
- **True Positive Rate (TPR)**: We observe a significant improvement in TPR (**84.11%**) compared to Min-K% Prob (**76.09%**) and Loss Attack (**64.03%**).
- **False Positive Rate (FPR)**: Our approach has a significantly lower FPR (**22.93%**) compared to Min-K% Prob (**37.98%**) and Loss Attack (**41.21%**).
- **Area Under Curve (AUC)**: Our approach achieves an **AUC of 88.00%**, far surpassing the baselines (Min-K% Prob: 74.00%, Loss Attack: 64.00%).

### Performance Improvements:
- **Accuracy Improvement**: 21.97% increase over Min-K% Prob.
- **TPR Improvement**: 10.54% increase over Min-K% Prob.
- **FPR Improvement**: 39.62% decrease over Min-K% Prob.
- **AUC Improvement**: 18.91% increase over Min-K% Prob.

## Conclusion
The results clearly demonstrate the effectiveness and robustness of **Natural-DaCoDe** in handling text data contamination detection tasks. Our approach significantly outperforms the state-of-the-art baselines in all key metrics, making it an excellent choice for generalizing contamination detection beyond code-specific tasks.

Given the widespread adoption of **ChatGPT 3.5** and its versatility across various tasks, the evaluation presented here is highly relevant for real-world text generation challenges.

## Repository Contents
- `main.py`: Implementation of the **Natural-DaCoDe** approach for text completion tasks.
- `svm_classifier.py`: Code to train the SVM classifier for contamination detection.
- `wikimia_dataset.csv`: The WIKIMIA dataset used for evaluation.
- `evaluation_results.pdf`: A detailed report on the performance evaluation.
  
## Installation
To run the code, ensure you have the following dependencies installed:

```bash
pip install -r requirements.txt

